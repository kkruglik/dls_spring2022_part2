В этом задании вам предстоит попрактиковаться в решении задачи машинного перевода. В решении этой задачи вам поможет модель Seq2Seq c использованием механизма внимания, то есть attention. Основная часть работа за вас сделана. Вам остается дописать архитектуру в файл modules.py. А именно вам придется дописать классы: Attention, DecoderWithAttention. В jupyter notebook вам остается определить гиперпараметры вашей архитектуры из файла modules.py и запустить процесс обучения сети. При изменении файла modules.py вам достаточно перезапустить ячеку с import и reload этого модуля. Для выполнения работы вам поможет семинар.

Результатом вашей работы будет готовый jupyter notebook (в формате .ipynb, в этом формате можно скачать файл из Google Colab: file->Download .ipynb) с заполненными пропусками и modules.py также с заполненными пропусками.